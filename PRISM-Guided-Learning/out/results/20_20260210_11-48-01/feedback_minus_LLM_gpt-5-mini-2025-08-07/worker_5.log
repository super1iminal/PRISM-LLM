2026-02-10 12:32:37,136 - INFO - SimplifiedVerifier initialized with 3 goals, 6 requirements
2026-02-10 12:32:37,144 - INFO - Policy initialized with 72 states.
2026-02-10 12:32:37,150 - INFO - Planning for goal 1 at position (2, 0)
2026-02-10 12:32:37,175 - INFO - Calling LLM for goal 1...
2026-02-10 12:32:37,175 - INFO - === PROMPT for goal 1 ===
You are an expert path planner working on formulating paths that meet formal requirements.

Your task is to create a best-action policy for a grid world — choose one action per cell that guides the agent from any position to the goal while avoiding static obstacles, future goals, and moving obstacles.

The grid world is 3 x 3. Here is the visual layout:

  0 1 2
0 S . F
1 . . F
2 G . .

Legend:
- 'S' = Start position (0,0) - the initial state
- 'G' = Current goal position you must reach
- 'X' = Static obstacle (CANNOT enter - you will bounce back)
- 'F' = Future goal (treat as obstacle for now - avoid it)
- 'M' = Moving obstacle patrol path (avoid if possible)
- '.' = Empty cell you can move through


COORDINATE SYSTEM:
- Position format: (row, col) where row is Y-axis, col is X-axis
- (0,0) is in the TOP-LEFT corner
- Row increases DOWNWARD (0 → 1 → 2...)
- Column increases RIGHTWARD (0 → 1 → 2...)

ACTIONS - pick ONE best action per state:
- 0 = UP: Move to (row-1, col) - DECREASES row
- 1 = RIGHT: Move to (row, col+1) - INCREASES column
- 2 = DOWN: Move to (row+1, col) - INCREASES row
- 3 = LEFT: Move to (row, col-1) - DECREASES column

ACTION EXAMPLES:
From (0,0): UP→(0,0), RIGHT→(0,1), DOWN→(1,0), LEFT→(0,0)
From (0,1): UP→(0,1), RIGHT→(0,2), DOWN→(1,1), LEFT→(0,0)
From (1,0): UP→(0,0), RIGHT→(1,1), DOWN→(2,0), LEFT→(1,0)


TASK DETAILS:
- Static obstacles: [] (marked as 'X')
- Future goals to avoid: [(1, 2), (0, 2)] (marked as 'F')
- Moving obstacles: [] (marked as 'M')
- Your current goal: (2, 0) (marked as 'G')

STOCHASTIC EXECUTION:
When you choose an action, the agent executes it with uncertainty:
- 70% probability: Moves in the intended direction
- 15% probability: Slips 90° LEFT of intended direction
- 15% probability: Slips 90° RIGHT of intended direction

Example: If you choose DOWN, there's a 70% chance of going DOWN, 15% chance of going LEFT, and 15% chance of going RIGHT.

This means your paths should be ROBUST - avoid routes that pass adjacent to obstacles since slips could cause collisions.

CRITICAL REQUIREMENTS:
1. You MUST provide the best action for ALL 9 states in the 3x3 grid
2. Never plan a path through obstacles (X) or future goals (F)
2a. Avoid moving obstacles (M) along their patrol paths if possible
3. The best action should create a path from ANY position to the goal
4. If a cell is an obstacle (X, M) or future goal (F), provide an escape action (how to exit if accidentally there due to stochastic slip)

Now provide the best action (0-3) for each state.

2026-02-10 12:33:57,956 - INFO - LLM Response received.
2026-02-10 12:33:57,956 - INFO - [StateAction(x=0, y=0, best_action=2), StateAction(x=0, y=1, best_action=3), StateAction(x=0, y=2, best_action=0), StateAction(x=1, y=0, best_action=2), StateAction(x=1, y=1, best_action=3), StateAction(x=1, y=2, best_action=2), StateAction(x=2, y=0, best_action=3), StateAction(x=2, y=1, best_action=3), StateAction(x=2, y=2, best_action=2)]
2026-02-10 12:33:57,956 - INFO - Setting action for state (0, 0, False, False, False) to 2
2026-02-10 12:33:57,956 - INFO - Setting action for state (0, 1, False, False, False) to 3
2026-02-10 12:33:57,956 - INFO - Setting action for state (0, 2, False, False, False) to 0
2026-02-10 12:33:57,959 - INFO - Setting action for state (1, 0, False, False, False) to 2
2026-02-10 12:33:57,959 - INFO - Setting action for state (1, 1, False, False, False) to 3
2026-02-10 12:33:57,959 - INFO - Setting action for state (1, 2, False, False, False) to 2
2026-02-10 12:33:57,959 - INFO - Setting action for state (2, 0, False, False, False) to 3
2026-02-10 12:33:57,959 - INFO - Setting action for state (2, 1, False, False, False) to 3
2026-02-10 12:33:57,961 - INFO - Setting action for state (2, 2, False, False, False) to 2
2026-02-10 12:33:57,961 - INFO - Planning for goal 2 at position (1, 2)
2026-02-10 12:33:57,963 - INFO - Calling LLM for goal 2...
2026-02-10 12:33:57,963 - INFO - === PROMPT for goal 2 ===
You are an expert path planner working on formulating paths that meet formal requirements.

Your task is to create a best-action policy for a grid world — choose one action per cell that guides the agent from any position to the goal while avoiding static obstacles, future goals, and moving obstacles.

The grid world is 3 x 3. Here is the visual layout:

  0 1 2
0 S . F
1 . . G
2 . . .

Legend:
- 'S' = Start position (0,0) - the initial state
- 'G' = Current goal position you must reach
- 'X' = Static obstacle (CANNOT enter - you will bounce back)
- 'F' = Future goal (treat as obstacle for now - avoid it)
- 'M' = Moving obstacle patrol path (avoid if possible)
- '.' = Empty cell you can move through


COORDINATE SYSTEM:
- Position format: (row, col) where row is Y-axis, col is X-axis
- (0,0) is in the TOP-LEFT corner
- Row increases DOWNWARD (0 → 1 → 2...)
- Column increases RIGHTWARD (0 → 1 → 2...)

ACTIONS - pick ONE best action per state:
- 0 = UP: Move to (row-1, col) - DECREASES row
- 1 = RIGHT: Move to (row, col+1) - INCREASES column
- 2 = DOWN: Move to (row+1, col) - INCREASES row
- 3 = LEFT: Move to (row, col-1) - DECREASES column

ACTION EXAMPLES:
From (0,0): UP→(0,0), RIGHT→(0,1), DOWN→(1,0), LEFT→(0,0)
From (0,1): UP→(0,1), RIGHT→(0,2), DOWN→(1,1), LEFT→(0,0)
From (1,0): UP→(0,0), RIGHT→(1,1), DOWN→(2,0), LEFT→(1,0)


TASK DETAILS:
- Static obstacles: [] (marked as 'X')
- Future goals to avoid: [(0, 2)] (marked as 'F')
- Moving obstacles: [] (marked as 'M')
- Your current goal: (1, 2) (marked as 'G')

STOCHASTIC EXECUTION:
When you choose an action, the agent executes it with uncertainty:
- 70% probability: Moves in the intended direction
- 15% probability: Slips 90° LEFT of intended direction
- 15% probability: Slips 90° RIGHT of intended direction

Example: If you choose DOWN, there's a 70% chance of going DOWN, 15% chance of going LEFT, and 15% chance of going RIGHT.

This means your paths should be ROBUST - avoid routes that pass adjacent to obstacles since slips could cause collisions.

CRITICAL REQUIREMENTS:
1. You MUST provide the best action for ALL 9 states in the 3x3 grid
2. Never plan a path through obstacles (X) or future goals (F)
2a. Avoid moving obstacles (M) along their patrol paths if possible
3. The best action should create a path from ANY position to the goal
4. If a cell is an obstacle (X, M) or future goal (F), provide an escape action (how to exit if accidentally there due to stochastic slip)

Now provide the best action (0-3) for each state.

2026-02-10 12:35:19,604 - INFO - LLM Response received.
2026-02-10 12:35:19,604 - INFO - [StateAction(x=0, y=0, best_action=2), StateAction(x=0, y=1, best_action=3), StateAction(x=0, y=2, best_action=2), StateAction(x=1, y=0, best_action=1), StateAction(x=1, y=1, best_action=1), StateAction(x=1, y=2, best_action=2), StateAction(x=2, y=0, best_action=1), StateAction(x=2, y=1, best_action=1), StateAction(x=2, y=2, best_action=0)]
2026-02-10 12:35:19,604 - INFO - Setting action for state (0, 0, True, False, False) to 2
2026-02-10 12:35:19,604 - INFO - Setting action for state (0, 1, True, False, False) to 3
2026-02-10 12:35:19,604 - INFO - Setting action for state (0, 2, True, False, False) to 2
2026-02-10 12:35:19,606 - INFO - Setting action for state (1, 0, True, False, False) to 1
2026-02-10 12:35:19,606 - INFO - Setting action for state (1, 1, True, False, False) to 1
2026-02-10 12:35:19,606 - INFO - Setting action for state (1, 2, True, False, False) to 2
2026-02-10 12:35:19,608 - INFO - Setting action for state (2, 0, True, False, False) to 1
2026-02-10 12:35:19,608 - INFO - Setting action for state (2, 1, True, False, False) to 1
2026-02-10 12:35:19,608 - INFO - Setting action for state (2, 2, True, False, False) to 0
2026-02-10 12:35:19,610 - INFO - Planning for goal 3 at position (0, 2)
2026-02-10 12:35:19,610 - INFO - Calling LLM for goal 3...
2026-02-10 12:35:19,610 - INFO - === PROMPT for goal 3 ===
You are an expert path planner working on formulating paths that meet formal requirements.

Your task is to create a best-action policy for a grid world — choose one action per cell that guides the agent from any position to the goal while avoiding static obstacles, future goals, and moving obstacles.

The grid world is 3 x 3. Here is the visual layout:

  0 1 2
0 S . G
1 . . .
2 . . .

Legend:
- 'S' = Start position (0,0) - the initial state
- 'G' = Current goal position you must reach
- 'X' = Static obstacle (CANNOT enter - you will bounce back)
- 'F' = Future goal (treat as obstacle for now - avoid it)
- 'M' = Moving obstacle patrol path (avoid if possible)
- '.' = Empty cell you can move through


COORDINATE SYSTEM:
- Position format: (row, col) where row is Y-axis, col is X-axis
- (0,0) is in the TOP-LEFT corner
- Row increases DOWNWARD (0 → 1 → 2...)
- Column increases RIGHTWARD (0 → 1 → 2...)

ACTIONS - pick ONE best action per state:
- 0 = UP: Move to (row-1, col) - DECREASES row
- 1 = RIGHT: Move to (row, col+1) - INCREASES column
- 2 = DOWN: Move to (row+1, col) - INCREASES row
- 3 = LEFT: Move to (row, col-1) - DECREASES column

ACTION EXAMPLES:
From (0,0): UP→(0,0), RIGHT→(0,1), DOWN→(1,0), LEFT→(0,0)
From (0,1): UP→(0,1), RIGHT→(0,2), DOWN→(1,1), LEFT→(0,0)
From (1,0): UP→(0,0), RIGHT→(1,1), DOWN→(2,0), LEFT→(1,0)


TASK DETAILS:
- Static obstacles: [] (marked as 'X')
- Future goals to avoid: [] (marked as 'F')
- Moving obstacles: [] (marked as 'M')
- Your current goal: (0, 2) (marked as 'G')

STOCHASTIC EXECUTION:
When you choose an action, the agent executes it with uncertainty:
- 70% probability: Moves in the intended direction
- 15% probability: Slips 90° LEFT of intended direction
- 15% probability: Slips 90° RIGHT of intended direction

Example: If you choose DOWN, there's a 70% chance of going DOWN, 15% chance of going LEFT, and 15% chance of going RIGHT.

This means your paths should be ROBUST - avoid routes that pass adjacent to obstacles since slips could cause collisions.

CRITICAL REQUIREMENTS:
1. You MUST provide the best action for ALL 9 states in the 3x3 grid
2. Never plan a path through obstacles (X) or future goals (F)
2a. Avoid moving obstacles (M) along their patrol paths if possible
3. The best action should create a path from ANY position to the goal
4. If a cell is an obstacle (X, M) or future goal (F), provide an escape action (how to exit if accidentally there due to stochastic slip)

Now provide the best action (0-3) for each state.

2026-02-10 12:35:48,131 - INFO - LLM Response received.
2026-02-10 12:35:48,131 - INFO - [StateAction(x=0, y=0, best_action=1), StateAction(x=0, y=1, best_action=1), StateAction(x=0, y=2, best_action=0), StateAction(x=1, y=0, best_action=1), StateAction(x=1, y=1, best_action=1), StateAction(x=1, y=2, best_action=0), StateAction(x=2, y=0, best_action=1), StateAction(x=2, y=1, best_action=1), StateAction(x=2, y=2, best_action=0)]
2026-02-10 12:35:48,132 - INFO - Setting action for state (0, 0, True, True, False) to 1
2026-02-10 12:35:48,132 - INFO - Setting action for state (0, 1, True, True, False) to 1
2026-02-10 12:35:48,134 - INFO - Setting action for state (0, 2, True, True, False) to 0
2026-02-10 12:35:48,136 - INFO - Setting action for state (1, 0, True, True, False) to 1
2026-02-10 12:35:48,138 - INFO - Setting action for state (1, 1, True, True, False) to 1
2026-02-10 12:35:48,140 - INFO - Setting action for state (1, 2, True, True, False) to 0
2026-02-10 12:35:48,142 - INFO - Setting action for state (2, 0, True, True, False) to 1
2026-02-10 12:35:48,144 - INFO - Setting action for state (2, 1, True, True, False) to 1
2026-02-10 12:35:48,146 - INFO - Setting action for state (2, 2, True, True, False) to 0
2026-02-10 12:35:48,150 - DEBUG - PRISM Model:
2026-02-10 12:35:48,150 - DEBUG - dtmc

const int N = 3;

module gridworld
  x : [0..2] init 0;
  y : [0..2] init 0;
  g1 : bool init false;
  g2 : bool init false;
  g3 : bool init false;

  [] (x=0 & y=0 & g1=false & g2=false & g3=false) -> 0.7:(x'=1) & (y'=0) & (g1'=false) & (g2'=false) & (g3'=false) + 0.15:(x'=0) & (y'=1) & (g1'=false) & (g2'=false) & (g3'=false) + 0.15:(x'=0) & (y'=0) & (g1'=false) & (g2'=false) & (g3'=false);
  [] (x=0 & y=0 & g1=false & g2=false & g3=true) -> 0.7:(x'=1) & (y'=0) & (g1'=false) & (g2'=false) & (g3'=true) + 0.15:(x'=0) & (y'=1) & (g1'=false) & (g2'=false) & (g3'=true) + 0.15:(x'=0) & (y'=0) & (g1'=false) & (g2'=false) & (g3'=true);
  [] (x=0 & y=0 & g1=false & g2=true & g3=false) -> 0.7:(x'=1) & (y'=0) & (g1'=false) & (g2'=true) & (g3'=false) + 0.15:(x'=0) & (y'=1) & (g1'=false) & (g2'=true) & (g3'=false) + 0.15:(x'=0) & (y'=0) & (g1'=false) & (g2'=true) & (g3'=false);
  [] (x=0 & y=0 & g1=false & g2=true & g3=true) -> 0.7:(x'=1) & (y'=0) & (g1'=false) & (g2'=true) & (g3'=true) + 0.15:(x'=0) & (y'=1) & (g1'=false) & (g2'=true) & (g3'=true) + 0.15:(x'=0) & (y'=0) & (g1'=false) & (g2'=true) & (g3'=true);
  [] (x=0 & y=0 & g1=true & g2=false & g3=false) -> 0.7:(x'=1) & (y'=0) & (g1'=true) & (g2'=false) & (g3'=false) + 0.15:(x'=0) & (y'=1) & (g1'=true) & (g2'=false) & (g3'=false) + 0.15:(x'=0) & (y'=0) & (g1'=true) & (g2'=false) & (g3'=false);
  [] (x=0 & y=0 & g1=true & g2=false & g3=true) -> 0.7:(x'=1) & (y'=0) & (g1'=true) & (g2'=false) & (g3'=true) + 0.15:(x'=0) & (y'=1) & (g1'=true) & (g2'=false) & (g3'=true) + 0.15:(x'=0) & (y'=0) & (g1'=true) & (g2'=false) & (g3'=true);
  [] (x=0 & y=0 & g1=true & g2=true & g3=false) -> 0.7:(x'=0) & (y'=1) & (g1'=true) & (g2'=true) & (g3'=false) + 0.15:(x'=0) & (y'=0) & (g1'=true) & (g2'=true) & (g3'=false) + 0.15:(x'=1) & (y'=0) & (g1'=true) & (g2'=true) & (g3'=false);
  [] (x=0 & y=0 & g1=true & g2=true & g3=true) -> 0.7:(x'=1) & (y'=0) & (g1'=true) & (g2'=true) & (g3'=true) + 0.15:(x'=0) & (y'=1) & (g1'=true) & (g2'=true) & (g3'=true) + 0.15:(x'=0) & (y'=0) & (g1'=true) & (g2'=true) & (g3'=true);
  [] (x=0 & y=1 & g1=false & g2=false & g3=false) -> 0.7:(x'=0) & (y'=0) & (g1'=false) & (g2'=false) & (g3'=false) + 0.15:(x'=1) & (y'=1) & (g1'=false) & (g2'=false) & (g3'=false) + 0.15:(x'=0) & (y'=1) & (g1'=false) & (g2'=false) & (g3'=false);
  [] (x=0 & y=1 & g1=false & g2=false & g3=true) -> 0.7:(x'=1) & (y'=1) & (g1'=false) & (g2'=false) & (g3'=true) + 0.15:(x'=0) & (y'=2) & (g1'=false) & (g2'=false) & (g3'=true) + 0.15:(x'=0) & (y'=0) & (g1'=false) & (g2'=false) & (g3'=true);
  [] (x=0 & y=1 & g1=false & g2=true & g3=false) -> 0.7:(x'=1) & (y'=1) & (g1'=false) & (g2'=true) & (g3'=false) + 0.15:(x'=0) & (y'=2) & (g1'=false) & (g2'=true) & (g3'=true) + 0.15:(x'=0) & (y'=0) & (g1'=false) & (g2'=true) & (g3'=false);
  [] (x=0 & y=1 & g1=false & g2=true & g3=true) -> 0.7:(x'=1) & (y'=1) & (g1'=false) & (g2'=true) & (g3'=true) + 0.15:(x'=0) & (y'=2) & (g1'=false) & (g2'=true) & (g3'=true) + 0.15:(x'=0) & (y'=0) & (g1'=false) & (g2'=true) & (g3'=true);
  [] (x=0 & y=1 & g1=true & g2=false & g3=false) -> 0.7:(x'=0) & (y'=0) & (g1'=true) & (g2'=false) & (g3'=false) + 0.15:(x'=1) & (y'=1) & (g1'=true) & (g2'=false) & (g3'=false) + 0.15:(x'=0) & (y'=1) & (g1'=true) & (g2'=false) & (g3'=false);
  [] (x=0 & y=1 & g1=true & g2=false & g3=true) -> 0.7:(x'=1) & (y'=1) & (g1'=true) & (g2'=false) & (g3'=true) + 0.15:(x'=0) & (y'=2) & (g1'=true) & (g2'=false) & (g3'=true) + 0.15:(x'=0) & (y'=0) & (g1'=true) & (g2'=false) & (g3'=true);
  [] (x=0 & y=1 & g1=true & g2=true & g3=false) -> 0.7:(x'=0) & (y'=2) & (g1'=true) & (g2'=true) & (g3'=true) + 0.15:(x'=0) & (y'=1) & (g1'=true) & (g2'=true) & (g3'=false) + 0.15:(x'=1) & (y'=1) & (g1'=true) & (g2'=true) & (g3'=false);
  [] (x=0 & y=1 & g1=true & g2=true & g3=true) -> 0.7:(x'=1) & (y'=1) & (g1'=true) & (g2'=true) & (g3'=true) + 0.15:(x'=0) & (y'=2) & (g1'=true) & (g2'=true) & (g3'=true) + 0.15:(x'=0) & (y'=0) & (g1'=true) & (g2'=true) & (g3'=true);
  [] (x=0 & y=2 & g1=false & g2=false & g3=false) -> 0.7:(x'=0) & (y'=2) & (g1'=false) & (g2'=false) & (g3'=false) + 0.15:(x'=0) & (y'=1) & (g1'=false) & (g2'=false) & (g3'=false) + 0.15:(x'=0) & (y'=2) & (g1'=false) & (g2'=false) & (g3'=false);
  [] (x=0 & y=2 & g1=false & g2=false & g3=true) -> 0.7:(x'=1) & (y'=2) & (g1'=false) & (g2'=false) & (g3'=true) + 0.15:(x'=0) & (y'=2) & (g1'=false) & (g2'=false) & (g3'=true) + 0.15:(x'=0) & (y'=1) & (g1'=false) & (g2'=false) & (g3'=true);
  [] (x=0 & y=2 & g1=false & g2=true & g3=false) -> 0.7:(x'=1) & (y'=2) & (g1'=false) & (g2'=true) & (g3'=false) + 0.15:(x'=0) & (y'=2) & (g1'=false) & (g2'=true) & (g3'=true) + 0.15:(x'=0) & (y'=1) & (g1'=false) & (g2'=true) & (g3'=false);
  [] (x=0 & y=2 & g1=false & g2=true & g3=true) -> 0.7:(x'=1) & (y'=2) & (g1'=false) & (g2'=true) & (g3'=true) + 0.15:(x'=0) & (y'=2) & (g1'=false) & (g2'=true) & (g3'=true) + 0.15:(x'=0) & (y'=1) & (g1'=false) & (g2'=true) & (g3'=true);
  [] (x=0 & y=2 & g1=true & g2=false & g3=false) -> 0.7:(x'=1) & (y'=2) & (g1'=true) & (g2'=true) & (g3'=false) + 0.15:(x'=0) & (y'=2) & (g1'=true) & (g2'=false) & (g3'=false) + 0.15:(x'=0) & (y'=1) & (g1'=true) & (g2'=false) & (g3'=false);
  [] (x=0 & y=2 & g1=true & g2=false & g3=true) -> 0.7:(x'=1) & (y'=2) & (g1'=true) & (g2'=true) & (g3'=true) + 0.15:(x'=0) & (y'=2) & (g1'=true) & (g2'=false) & (g3'=true) + 0.15:(x'=0) & (y'=1) & (g1'=true) & (g2'=false) & (g3'=true);
  [] (x=0 & y=2 & g1=true & g2=true & g3=false) -> 0.7:(x'=0) & (y'=2) & (g1'=true) & (g2'=true) & (g3'=true) + 0.15:(x'=0) & (y'=1) & (g1'=true) & (g2'=true) & (g3'=false) + 0.15:(x'=0) & (y'=2) & (g1'=true) & (g2'=true) & (g3'=true);
  [] (x=0 & y=2 & g1=true & g2=true & g3=true) -> 0.7:(x'=1) & (y'=2) & (g1'=true) & (g2'=true) & (g3'=true) + 0.15:(x'=0) & (y'=2) & (g1'=true) & (g2'=true) & (g3'=true) + 0.15:(x'=0) & (y'=1) & (g1'=true) & (g2'=true) & (g3'=true);
  [] (x=1 & y=0 & g1=false & g2=false & g3=false) -> 0.7:(x'=2) & (y'=0) & (g1'=true) & (g2'=false) & (g3'=false) + 0.15:(x'=1) & (y'=1) & (g1'=false) & (g2'=false) & (g3'=false) + 0.15:(x'=1) & (y'=0) & (g1'=false) & (g2'=false) & (g3'=false);
  [] (x=1 & y=0 & g1=false & g2=false & g3=true) -> 0.7:(x'=2) & (y'=0) & (g1'=true) & (g2'=false) & (g3'=true) + 0.15:(x'=1) & (y'=1) & (g1'=false) & (g2'=false) & (g3'=true) + 0.15:(x'=1) & (y'=0) & (g1'=false) & (g2'=false) & (g3'=true);
  [] (x=1 & y=0 & g1=false & g2=true & g3=false) -> 0.7:(x'=2) & (y'=0) & (g1'=true) & (g2'=true) & (g3'=false) + 0.15:(x'=1) & (y'=1) & (g1'=false) & (g2'=true) & (g3'=false) + 0.15:(x'=1) & (y'=0) & (g1'=false) & (g2'=true) & (g3'=false);
  [] (x=1 & y=0 & g1=false & g2=true & g3=true) -> 0.7:(x'=2) & (y'=0) & (g1'=true) & (g2'=true) & (g3'=true) + 0.15:(x'=1) & (y'=1) & (g1'=false) & (g2'=true) & (g3'=true) + 0.15:(x'=1) & (y'=0) & (g1'=false) & (g2'=true) & (g3'=true);
  [] (x=1 & y=0 & g1=true & g2=false & g3=false) -> 0.7:(x'=1) & (y'=1) & (g1'=true) & (g2'=false) & (g3'=false) + 0.15:(x'=0) & (y'=0) & (g1'=true) & (g2'=false) & (g3'=false) + 0.15:(x'=2) & (y'=0) & (g1'=true) & (g2'=false) & (g3'=false);
  [] (x=1 & y=0 & g1=true & g2=false & g3=true) -> 0.7:(x'=2) & (y'=0) & (g1'=true) & (g2'=false) & (g3'=true) + 0.15:(x'=1) & (y'=1) & (g1'=true) & (g2'=false) & (g3'=true) + 0.15:(x'=1) & (y'=0) & (g1'=true) & (g2'=false) & (g3'=true);
  [] (x=1 & y=0 & g1=true & g2=true & g3=false) -> 0.7:(x'=1) & (y'=1) & (g1'=true) & (g2'=true) & (g3'=false) + 0.15:(x'=0) & (y'=0) & (g1'=true) & (g2'=true) & (g3'=false) + 0.15:(x'=2) & (y'=0) & (g1'=true) & (g2'=true) & (g3'=false);
  [] (x=1 & y=0 & g1=true & g2=true & g3=true) -> 0.7:(x'=2) & (y'=0) & (g1'=true) & (g2'=true) & (g3'=true) + 0.15:(x'=1) & (y'=1) & (g1'=true) & (g2'=true) & (g3'=true) + 0.15:(x'=1) & (y'=0) & (g1'=true) & (g2'=true) & (g3'=true);
  [] (x=1 & y=1 & g1=false & g2=false & g3=false) -> 0.7:(x'=1) & (y'=0) & (g1'=false) & (g2'=false) & (g3'=false) + 0.15:(x'=2) & (y'=1) & (g1'=false) & (g2'=false) & (g3'=false) + 0.15:(x'=0) & (y'=1) & (g1'=false) & (g2'=false) & (g3'=false);
  [] (x=1 & y=1 & g1=false & g2=false & g3=true) -> 0.7:(x'=2) & (y'=1) & (g1'=false) & (g2'=false) & (g3'=true) + 0.15:(x'=1) & (y'=2) & (g1'=false) & (g2'=false) & (g3'=true) + 0.15:(x'=1) & (y'=0) & (g1'=false) & (g2'=false) & (g3'=true);
  [] (x=1 & y=1 & g1=false & g2=true & g3=false) -> 0.7:(x'=2) & (y'=1) & (g1'=false) & (g2'=true) & (g3'=false) + 0.15:(x'=1) & (y'=2) & (g1'=false) & (g2'=true) & (g3'=false) + 0.15:(x'=1) & (y'=0) & (g1'=false) & (g2'=true) & (g3'=false);
  [] (x=1 & y=1 & g1=false & g2=true & g3=true) -> 0.7:(x'=2) & (y'=1) & (g1'=false) & (g2'=true) & (g3'=true) + 0.15:(x'=1) & (y'=2) & (g1'=false) & (g2'=true) & (g3'=true) + 0.15:(x'=1) & (y'=0) & (g1'=false) & (g2'=true) & (g3'=true);
  [] (x=1 & y=1 & g1=true & g2=false & g3=false) -> 0.7:(x'=1) & (y'=2) & (g1'=true) & (g2'=true) & (g3'=false) + 0.15:(x'=0) & (y'=1) & (g1'=true) & (g2'=false) & (g3'=false) + 0.15:(x'=2) & (y'=1) & (g1'=true) & (g2'=false) & (g3'=false);
  [] (x=1 & y=1 & g1=true & g2=false & g3=true) -> 0.7:(x'=2) & (y'=1) & (g1'=true) & (g2'=false) & (g3'=true) + 0.15:(x'=1) & (y'=2) & (g1'=true) & (g2'=true) & (g3'=true) + 0.15:(x'=1) & (y'=0) & (g1'=true) & (g2'=false) & (g3'=true);
  [] (x=1 & y=1 & g1=true & g2=true & g3=false) -> 0.7:(x'=1) & (y'=2) & (g1'=true) & (g2'=true) & (g3'=false) + 0.15:(x'=0) & (y'=1) & (g1'=true) & (g2'=true) & (g3'=false) + 0.15:(x'=2) & (y'=1) & (g1'=true) & (g2'=true) & (g3'=false);
  [] (x=1 & y=1 & g1=true & g2=true & g3=true) -> 0.7:(x'=2) & (y'=1) & (g1'=true) & (g2'=true) & (g3'=true) + 0.15:(x'=1) & (y'=2) & (g1'=true) & (g2'=true) & (g3'=true) + 0.15:(x'=1) & (y'=0) & (g1'=true) & (g2'=true) & (g3'=true);
  [] (x=1 & y=2 & g1=false & g2=false & g3=false) -> 0.7:(x'=2) & (y'=2) & (g1'=false) & (g2'=false) & (g3'=false) + 0.15:(x'=1) & (y'=2) & (g1'=false) & (g2'=false) & (g3'=false) + 0.15:(x'=1) & (y'=1) & (g1'=false) & (g2'=false) & (g3'=false);
  [] (x=1 & y=2 & g1=false & g2=false & g3=true) -> 0.7:(x'=2) & (y'=2) & (g1'=false) & (g2'=false) & (g3'=true) + 0.15:(x'=1) & (y'=2) & (g1'=false) & (g2'=false) & (g3'=true) + 0.15:(x'=1) & (y'=1) & (g1'=false) & (g2'=false) & (g3'=true);
  [] (x=1 & y=2 & g1=false & g2=true & g3=false) -> 0.7:(x'=2) & (y'=2) & (g1'=false) & (g2'=true) & (g3'=false) + 0.15:(x'=1) & (y'=2) & (g1'=false) & (g2'=true) & (g3'=false) + 0.15:(x'=1) & (y'=1) & (g1'=false) & (g2'=true) & (g3'=false);
  [] (x=1 & y=2 & g1=false & g2=true & g3=true) -> 0.7:(x'=2) & (y'=2) & (g1'=false) & (g2'=true) & (g3'=true) + 0.15:(x'=1) & (y'=2) & (g1'=false) & (g2'=true) & (g3'=true) + 0.15:(x'=1) & (y'=1) & (g1'=false) & (g2'=true) & (g3'=true);
  [] (x=1 & y=2 & g1=true & g2=false & g3=false) -> 0.7:(x'=2) & (y'=2) & (g1'=true) & (g2'=false) & (g3'=false) + 0.15:(x'=1) & (y'=2) & (g1'=true) & (g2'=true) & (g3'=false) + 0.15:(x'=1) & (y'=1) & (g1'=true) & (g2'=false) & (g3'=false);
  [] (x=1 & y=2 & g1=true & g2=false & g3=true) -> 0.7:(x'=2) & (y'=2) & (g1'=true) & (g2'=false) & (g3'=true) + 0.15:(x'=1) & (y'=2) & (g1'=true) & (g2'=true) & (g3'=true) + 0.15:(x'=1) & (y'=1) & (g1'=true) & (g2'=false) & (g3'=true);
  [] (x=1 & y=2 & g1=true & g2=true & g3=false) -> 0.7:(x'=0) & (y'=2) & (g1'=true) & (g2'=true) & (g3'=true) + 0.15:(x'=1) & (y'=1) & (g1'=true) & (g2'=true) & (g3'=false) + 0.15:(x'=1) & (y'=2) & (g1'=true) & (g2'=true) & (g3'=false);
  [] (x=1 & y=2 & g1=true & g2=true & g3=true) -> 0.7:(x'=2) & (y'=2) & (g1'=true) & (g2'=true) & (g3'=true) + 0.15:(x'=1) & (y'=2) & (g1'=true) & (g2'=true) & (g3'=true) + 0.15:(x'=1) & (y'=1) & (g1'=true) & (g2'=true) & (g3'=true);
  [] (x=2 & y=0 & g1=false & g2=false & g3=false) -> 0.7:(x'=2) & (y'=0) & (g1'=true) & (g2'=false) & (g3'=false) + 0.15:(x'=2) & (y'=0) & (g1'=true) & (g2'=false) & (g3'=false) + 0.15:(x'=1) & (y'=0) & (g1'=false) & (g2'=false) & (g3'=false);
  [] (x=2 & y=0 & g1=false & g2=false & g3=true) -> 0.7:(x'=2) & (y'=0) & (g1'=true) & (g2'=false) & (g3'=true) + 0.15:(x'=2) & (y'=1) & (g1'=false) & (g2'=false) & (g3'=true) + 0.15:(x'=2) & (y'=0) & (g1'=true) & (g2'=false) & (g3'=true);
  [] (x=2 & y=0 & g1=false & g2=true & g3=false) -> 0.7:(x'=2) & (y'=0) & (g1'=true) & (g2'=true) & (g3'=false) + 0.15:(x'=2) & (y'=1) & (g1'=false) & (g2'=true) & (g3'=false) + 0.15:(x'=2) & (y'=0) & (g1'=true) & (g2'=true) & (g3'=false);
  [] (x=2 & y=0 & g1=false & g2=true & g3=true) -> 0.7:(x'=2) & (y'=0) & (g1'=true) & (g2'=true) & (g3'=true) + 0.15:(x'=2) & (y'=1) & (g1'=false) & (g2'=true) & (g3'=true) + 0.15:(x'=2) & (y'=0) & (g1'=true) & (g2'=true) & (g3'=true);
  [] (x=2 & y=0 & g1=true & g2=false & g3=false) -> 0.7:(x'=2) & (y'=1) & (g1'=true) & (g2'=false) & (g3'=false) + 0.15:(x'=1) & (y'=0) & (g1'=true) & (g2'=false) & (g3'=false) + 0.15:(x'=2) & (y'=0) & (g1'=true) & (g2'=false) & (g3'=false);
  [] (x=2 & y=0 & g1=true & g2=false & g3=true) -> 0.7:(x'=2) & (y'=0) & (g1'=true) & (g2'=false) & (g3'=true) + 0.15:(x'=2) & (y'=1) & (g1'=true) & (g2'=false) & (g3'=true) + 0.15:(x'=2) & (y'=0) & (g1'=true) & (g2'=false) & (g3'=true);
  [] (x=2 & y=0 & g1=true & g2=true & g3=false) -> 0.7:(x'=2) & (y'=1) & (g1'=true) & (g2'=true) & (g3'=false) + 0.15:(x'=1) & (y'=0) & (g1'=true) & (g2'=true) & (g3'=false) + 0.15:(x'=2) & (y'=0) & (g1'=true) & (g2'=true) & (g3'=false);
  [] (x=2 & y=0 & g1=true & g2=true & g3=true) -> 0.7:(x'=2) & (y'=0) & (g1'=true) & (g2'=true) & (g3'=true) + 0.15:(x'=2) & (y'=1) & (g1'=true) & (g2'=true) & (g3'=true) + 0.15:(x'=2) & (y'=0) & (g1'=true) & (g2'=true) & (g3'=true);
  [] (x=2 & y=1 & g1=false & g2=false & g3=false) -> 0.7:(x'=2) & (y'=0) & (g1'=true) & (g2'=false) & (g3'=false) + 0.15:(x'=2) & (y'=1) & (g1'=false) & (g2'=false) & (g3'=false) + 0.15:(x'=1) & (y'=1) & (g1'=false) & (g2'=false) & (g3'=false);
  [] (x=2 & y=1 & g1=false & g2=false & g3=true) -> 0.7:(x'=2) & (y'=1) & (g1'=false) & (g2'=false) & (g3'=true) + 0.15:(x'=2) & (y'=2) & (g1'=false) & (g2'=false) & (g3'=true) + 0.15:(x'=2) & (y'=0) & (g1'=true) & (g2'=false) & (g3'=true);
  [] (x=2 & y=1 & g1=false & g2=true & g3=false) -> 0.7:(x'=2) & (y'=1) & (g1'=false) & (g2'=true) & (g3'=false) + 0.15:(x'=2) & (y'=2) & (g1'=false) & (g2'=true) & (g3'=false) + 0.15:(x'=2) & (y'=0) & (g1'=true) & (g2'=true) & (g3'=false);
  [] (x=2 & y=1 & g1=false & g2=true & g3=true) -> 0.7:(x'=2) & (y'=1) & (g1'=false) & (g2'=true) & (g3'=true) + 0.15:(x'=2) & (y'=2) & (g1'=false) & (g2'=true) & (g3'=true) + 0.15:(x'=2) & (y'=0) & (g1'=true) & (g2'=true) & (g3'=true);
  [] (x=2 & y=1 & g1=true & g2=false & g3=false) -> 0.7:(x'=2) & (y'=2) & (g1'=true) & (g2'=false) & (g3'=false) + 0.15:(x'=1) & (y'=1) & (g1'=true) & (g2'=false) & (g3'=false) + 0.15:(x'=2) & (y'=1) & (g1'=true) & (g2'=false) & (g3'=false);
  [] (x=2 & y=1 & g1=true & g2=false & g3=true) -> 0.7:(x'=2) & (y'=1) & (g1'=true) & (g2'=false) & (g3'=true) + 0.15:(x'=2) & (y'=2) & (g1'=true) & (g2'=false) & (g3'=true) + 0.15:(x'=2) & (y'=0) & (g1'=true) & (g2'=false) & (g3'=true);
  [] (x=2 & y=1 & g1=true & g2=true & g3=false) -> 0.7:(x'=2) & (y'=2) & (g1'=true) & (g2'=true) & (g3'=false) + 0.15:(x'=1) & (y'=1) & (g1'=true) & (g2'=true) & (g3'=false) + 0.15:(x'=2) & (y'=1) & (g1'=true) & (g2'=true) & (g3'=false);
  [] (x=2 & y=1 & g1=true & g2=true & g3=true) -> 0.7:(x'=2) & (y'=1) & (g1'=true) & (g2'=true) & (g3'=true) + 0.15:(x'=2) & (y'=2) & (g1'=true) & (g2'=true) & (g3'=true) + 0.15:(x'=2) & (y'=0) & (g1'=true) & (g2'=true) & (g3'=true);
  [] (x=2 & y=2 & g1=false & g2=false & g3=false) -> 0.7:(x'=2) & (y'=2) & (g1'=false) & (g2'=false) & (g3'=false) + 0.15:(x'=2) & (y'=2) & (g1'=false) & (g2'=false) & (g3'=false) + 0.15:(x'=2) & (y'=1) & (g1'=false) & (g2'=false) & (g3'=false);
  [] (x=2 & y=2 & g1=false & g2=false & g3=true) -> 0.7:(x'=2) & (y'=2) & (g1'=false) & (g2'=false) & (g3'=true) + 0.15:(x'=2) & (y'=2) & (g1'=false) & (g2'=false) & (g3'=true) + 0.15:(x'=2) & (y'=1) & (g1'=false) & (g2'=false) & (g3'=true);
  [] (x=2 & y=2 & g1=false & g2=true & g3=false) -> 0.7:(x'=2) & (y'=2) & (g1'=false) & (g2'=true) & (g3'=false) + 0.15:(x'=2) & (y'=2) & (g1'=false) & (g2'=true) & (g3'=false) + 0.15:(x'=2) & (y'=1) & (g1'=false) & (g2'=true) & (g3'=false);
  [] (x=2 & y=2 & g1=false & g2=true & g3=true) -> 0.7:(x'=2) & (y'=2) & (g1'=false) & (g2'=true) & (g3'=true) + 0.15:(x'=2) & (y'=2) & (g1'=false) & (g2'=true) & (g3'=true) + 0.15:(x'=2) & (y'=1) & (g1'=false) & (g2'=true) & (g3'=true);
  [] (x=2 & y=2 & g1=true & g2=false & g3=false) -> 0.7:(x'=1) & (y'=2) & (g1'=true) & (g2'=true) & (g3'=false) + 0.15:(x'=2) & (y'=1) & (g1'=true) & (g2'=false) & (g3'=false) + 0.15:(x'=2) & (y'=2) & (g1'=true) & (g2'=false) & (g3'=false);
  [] (x=2 & y=2 & g1=true & g2=false & g3=true) -> 0.7:(x'=2) & (y'=2) & (g1'=true) & (g2'=false) & (g3'=true) + 0.15:(x'=2) & (y'=2) & (g1'=true) & (g2'=false) & (g3'=true) + 0.15:(x'=2) & (y'=1) & (g1'=true) & (g2'=false) & (g3'=true);
  [] (x=2 & y=2 & g1=true & g2=true & g3=false) -> 0.7:(x'=1) & (y'=2) & (g1'=true) & (g2'=true) & (g3'=false) + 0.15:(x'=2) & (y'=1) & (g1'=true) & (g2'=true) & (g3'=false) + 0.15:(x'=2) & (y'=2) & (g1'=true) & (g2'=true) & (g3'=false);
  [] (x=2 & y=2 & g1=true & g2=true & g3=true) -> 0.7:(x'=2) & (y'=2) & (g1'=true) & (g2'=true) & (g3'=true) + 0.15:(x'=2) & (y'=2) & (g1'=true) & (g2'=true) & (g3'=true) + 0.15:(x'=2) & (y'=1) & (g1'=true) & (g2'=true) & (g3'=true);
endmodule

// Labels for properties
label "at_goal1" = x=2 & y=0;
label "at_goal2" = x=1 & y=2;
label "at_goal3" = x=0 & y=2;
label "in_seg1" = !g1;
label "in_seg2" = g1 & !g2;
label "in_seg3" = g2 & !g3;
2026-02-10 12:35:48,150 - DEBUG - Properties:
2026-02-10 12:35:48,150 - DEBUG - P=? [ F "at_goal1" ];
P=? [ F "at_goal2" ];
P=? [ F "at_goal3" ];
P=? [ !"at_goal2" U "at_goal1" ];
P=? [ !"at_goal3" U ("at_goal1" & (!"at_goal3" U "at_goal2")) ];
P=? [ (!"at_goal2" U "at_goal1") & (!"at_goal3" U ("at_goal1" & (!"at_goal3" U "at_goal2"))) ];

2026-02-10 12:35:48,153 - DEBUG - Running PRISM command: /u/asherarya/prism-4.10-src/prism/bin/prism /tmp/tmp91f5yxbq.nm /tmp/tmpnd5gl82s.props -explicit -javamaxmem 4g -maxiters 1000000 -power -verbose -exportstates PRISM-Guided-Learning/out/logs/states.txt
2026-02-10 12:35:49,591 - DEBUG - PRISM stdout:
2026-02-10 12:35:49,591 - DEBUG - PRISM
=====

Version: 4.10
Date: Tue Feb 10 12:35:48 EST 2026
Hostname: comps1
Memory limits: cudd=1g, java(heap)=4g
Command line: prism /tmp/tmp91f5yxbq.nm /tmp/tmpnd5gl82s.props -explicit -javamaxmem 4g -maxiters 1000000 -power -verbose -exportstates PRISM-Guided-Learning/out/logs/states.txt

Parsing PRISM model file "/tmp/tmp91f5yxbq.nm"...

Type:        DTMC
Modules:     gridworld
Actions:     []
Variables:   x y g1 g2 g3
Labels:      "at_goal1" "at_goal2" "at_goal3" "in_seg1" "in_seg2" "in_seg3"

Parsing properties file "/tmp/tmpnd5gl82s.props"...

6 properties:
(1) P=? [ F "at_goal1" ]
(2) P=? [ F "at_goal2" ]
(3) P=? [ F "at_goal3" ]
(4) P=? [ !"at_goal2" U "at_goal1" ]
(5) P=? [ !"at_goal3" U ("at_goal1"&(!"at_goal3" U "at_goal2")) ]
(6) P=? [ (!"at_goal2" U "at_goal1")&(!"at_goal3" U ("at_goal1"&(!"at_goal3" U "at_goal2"))) ]

Building model (engine:explicit)...

Computing reachable states... 26 states
Reachable states exploration and model construction done in 0.016 secs.
Sorting reachable states list...

Time for model construction: 0.069 seconds.

Type:        DTMC
States:      26 (1 initial)
Transitions: 76

Exporting reachable states in plain text format to file "PRISM-Guided-Learning/out/logs/states.txt"...

Error: Could not open file "PRISM-Guided-Learning/out/logs/states.txt" for output.

---------------------------------------------------------------------

Model checking: P=? [ F "at_goal1" ]

Starting probabilistic reachability...
Calculating predecessor relation for discrete-time Markov chain...  done (0.002 seconds)
Starting Prob0...
Prob0 took 0.003 seconds.
Starting Prob1...
Prob1 took 0.0 seconds.
target=2, yes=26, no=0, maybe=0
Probabilistic reachability took 0.014 seconds.

Probabilities (non-zero only) for all states:
0:(0,0,false,false,false)=1.0
1:(0,0,true,false,false)=1.0
2:(0,0,true,true,true)=1.0
3:(0,1,false,false,false)=1.0
4:(0,1,true,false,false)=1.0
5:(0,1,true,true,false)=1.0
6:(0,1,true,true,true)=1.0
7:(0,2,true,true,true)=1.0
8:(1,0,false,false,false)=1.0
9:(1,0,true,false,false)=1.0
10:(1,0,true,true,true)=1.0
11:(1,1,false,false,false)=1.0
12:(1,1,true,false,false)=1.0
13:(1,1,true,true,false)=1.0
14:(1,1,true,true,true)=1.0
15:(1,2,true,true,false)=1.0
16:(1,2,true,true,true)=1.0
17:(2,0,true,false,false)=1.0
18:(2,0,true,true,true)=1.0
19:(2,1,false,false,false)=1.0
20:(2,1,true,false,false)=1.0
21:(2,1,true,true,false)=1.0
22:(2,1,true,true,true)=1.0
23:(2,2,true,false,false)=1.0
24:(2,2,true,true,false)=1.0
25:(2,2,true,true,true)=1.0

Value in the initial state: 1.0

Time for model checking: 0.021 seconds.

Result: 1.0 (exact floating point)

---------------------------------------------------------------------

Model checking: P=? [ F "at_goal2" ]

Starting probabilistic reachability...
Starting Prob0...
Prob0 took 0.0 seconds.
Starting Prob1...
Prob1 took 0.0 seconds.
target=2, yes=14, no=3, maybe=9
Starting value iteration (with Power method)...
Value iteration (with Power method) took 21 iterations, 567 multiplications and 0.005 seconds.
Probabilistic reachability took 0.007 seconds.

Probabilities (non-zero only) for all states:
0:(0,0,false,false,false)=1.0
1:(0,0,true,false,false)=1.0
2:(0,0,true,true,true)=0.0661330077703792
3:(0,1,false,false,false)=1.0
4:(0,1,true,false,false)=1.0
5:(0,1,true,true,false)=0.8876233687076832
6:(0,1,true,true,true)=0.24786549322486484
7:(0,2,true,true,true)=0.8672703811488152
8:(1,0,false,false,false)=1.0
9:(1,0,true,false,false)=1.0
10:(1,0,true,true,true)=0.027190332326273173
11:(1,1,false,false,false)=1.0
12:(1,1,true,false,false)=1.0
13:(1,1,true,true,false)=0.9826044411921926
14:(1,1,true,true,true)=0.1540785498489359
15:(1,2,true,true,false)=1.0
16:(1,2,true,true,true)=1.0
17:(2,0,true,false,false)=1.0
19:(2,1,false,false,false)=1.0
20:(2,1,true,false,false)=1.0
21:(2,1,true,true,false)=0.9964073234233072
23:(2,2,true,false,false)=1.0
24:(2,2,true,true,false)=0.999365760141821

Value in the initial state: 1.0

Time for model checking: 0.008 seconds.

Result: 1.0 (+/- 9.485812115981087E-6 estimated; rel err 9.485812115981087E-6)

---------------------------------------------------------------------

Model checking: P=? [ F "at_goal3" ]

Starting probabilistic reachability...
Starting Prob0...
Prob0 took 0.0 seconds.
Starting Prob1...
Prob1 took 0.0 seconds.
target=1, yes=18, no=6, maybe=2
Starting value iteration (with Power method)...
Value iteration (with Power method) took 12 iterations, 72 multiplications and 0.0 seconds.
Probabilistic reachability took 0.0 seconds.

Probabilities (non-zero only) for all states:
0:(0,0,false,false,false)=1.0
1:(0,0,true,false,false)=1.0
2:(0,0,true,true,true)=0.02719032862557348
3:(0,1,false,false,false)=1.0
4:(0,1,true,false,false)=1.0
5:(0,1,true,true,false)=1.0
6:(0,1,true,true,true)=0.1540785475617224
7:(0,2,true,true,true)=1.0
8:(1,0,false,false,false)=1.0
9:(1,0,true,false,false)=1.0
11:(1,1,false,false,false)=1.0
12:(1,1,true,false,false)=1.0
13:(1,1,true,true,false)=1.0
15:(1,2,true,true,false)=1.0
17:(2,0,true,false,false)=1.0
19:(2,1,false,false,false)=1.0
20:(2,1,true,false,false)=1.0
21:(2,1,true,true,false)=1.0
23:(2,2,true,false,false)=1.0
24:(2,2,true,true,false)=1.0

Value in the initial state: 1.0

Time for model checking: 0.001 seconds.

Result: 1.0 (+/- 4.246886541183531E-6 estimated; rel err 4.246886541183531E-6)

---------------------------------------------------------------------

Model checking: P=? [ !"at_goal2" U "at_goal1" ]

Starting probabilistic reachability...
Starting Prob0...
Prob0 took 0.0 seconds.
Starting Prob1...
Prob1 took 0.001 seconds.
target=2, yes=9, no=2, maybe=15
Starting value iteration (with Power method)...
Value iteration (with Power method) took 44 iterations, 1980 multiplications and 0.0 seconds.
Probabilistic reachability took 0.001 seconds.

Probabilities (non-zero only) for all states:
0:(0,0,false,false,false)=1.0
1:(0,0,true,false,false)=0.18960484476510892
2:(0,0,true,true,true)=0.9338669922191917
3:(0,1,false,false,false)=1.0
4:(0,1,true,false,false)=0.1605302875446147
5:(0,1,true,true,false)=0.11237649193333443
6:(0,1,true,true,true)=0.7521345067647445
7:(0,2,true,true,true)=0.13272961884083725
8:(1,0,false,false,false)=1.0
9:(1,0,true,false,false)=0.19583512906826928
10:(1,0,true,true,true)=0.972809667673716
11:(1,1,false,false,false)=1.0
12:(1,1,true,false,false)=0.024849157560777522
13:(1,1,true,true,false)=0.01739523303166348
14:(1,1,true,true,true)=0.8459214501510574
17:(2,0,true,false,false)=1.0
18:(2,0,true,true,true)=1.0
19:(2,1,false,false,false)=1.0
20:(2,1,true,false,false)=0.005130794503980872
21:(2,1,true,true,false)=0.0035917282777760844
22:(2,1,true,true,true)=1.0
23:(2,2,true,false,false)=9.054337220161503E-4
24:(2,2,true,true,false)=6.338344019559504E-4
25:(2,2,true,true,true)=1.0

Value in the initial state: 1.0

Time for model checking: 0.004 seconds.

Result: 1.0 (+/- 7.962304291646716E-6 estimated; rel err 7.962304291646716E-6)

---------------------------------------------------------------------

Model checking: P=? [ !"at_goal3" U ("at_goal1"&(!"at_goal3" U "at_goal2")) ]

Building deterministic automaton (for "L0" U ("L1"&("L0" U "L2")))...
DFA has 4 states, 1 goal states.
Time for DFA translation: 0.106 seconds.
Constructing DTMC-DFA product...
Time for product construction: 0.009 seconds, product has 26 states (1 initial), 76 transitions.

Skipping BSCC computation since acceptance is defined via goal states...

Computing reachability probabilities...

Starting probabilistic reachability...
Calculating predecessor relation for discrete-time Markov chain...  done (0.0 seconds)
Starting Prob0...
Prob0 took 0.0 seconds.
Starting Prob1...
Prob1 took 0.0 seconds.
target=14, yes=26, no=0, maybe=0
Probabilistic reachability took 0.001 seconds.

Probabilities (non-zero only) for all states:
0:(0,0,false,false,false)=1.0

Value in the initial state: 1.0

Time for model checking: 0.127 seconds.

Result: 1.0 (exact floating point)

---------------------------------------------------------------------

Model checking: P=? [ (!"at_goal2" U "at_goal1")&(!"at_goal3" U ("at_goal1"&(!"at_goal3" U "at_goal2"))) ]

Building deterministic automaton (for ("L0" U "L1")&("L2" U ("L1"&("L2" U !"L0"))))...
DFA has 4 states, 1 goal states.
Time for DFA translation: 0.003 seconds.
Constructing DTMC-DFA product...
Time for product construction: 0.001 seconds, product has 26 states (1 initial), 76 transitions.

Skipping BSCC computation since acceptance is defined via goal states...

Computing reachability probabilities...

Starting probabilistic reachability...
Calculating predecessor relation for discrete-time Markov chain...  done (0.0 seconds)
Starting Prob0...
Prob0 took 0.0 seconds.
Starting Prob1...
Prob1 took 0.0 seconds.
target=14, yes=26, no=0, maybe=0
Probabilistic reachability took 0.0 seconds.

Probabilities (non-zero only) for all states:
0:(0,0,false,false,false)=1.0

Value in the initial state: 1.0

Time for model checking: 0.006 seconds.

Result: 1.0 (exact floating point)


2026-02-10 12:35:49,591 - DEBUG - PRISM stderr:
2026-02-10 12:35:49,591 - DEBUG - 
2026-02-10 12:35:49,591 - DEBUG - Parsed probability: 1.0
2026-02-10 12:35:49,591 - DEBUG - Parsed probability: 1.0
2026-02-10 12:35:49,591 - DEBUG - Parsed probability: 1.0
2026-02-10 12:35:49,610 - DEBUG - Parsed probability: 1.0
2026-02-10 12:35:49,610 - DEBUG - Parsed probability: 1.0
2026-02-10 12:35:49,610 - DEBUG - Parsed probability: 1.0
2026-02-10 12:35:49,611 - INFO - PRISM Verification Results:
2026-02-10 12:35:49,617 - INFO -   Reach G1          = 1.0000 (weight: 0.167)
2026-02-10 12:35:49,617 - INFO -   Reach G2          = 1.0000 (weight: 0.167)
2026-02-10 12:35:49,617 - INFO -   Reach G3          = 1.0000 (weight: 0.167)
2026-02-10 12:35:49,617 - INFO -   G1 before G2      = 1.0000 (weight: 0.250)
2026-02-10 12:35:49,617 - INFO -   G1,G2 before G3   = 1.0000 (weight: 0.250)
2026-02-10 12:35:49,624 - INFO -   Complete sequence = 1.0000 (info only)
2026-02-10 12:35:49,626 - INFO - Combined Score: 1.0000
2026-02-10 12:35:49,626 - INFO - Initial LTL Score: 1.0
2026-02-10 12:35:49,627 - INFO - All probabilities meet threshold after 1 attempts
2026-02-10 12:35:49,627 - INFO - Final LTL Score (Feedback Minus LLM): 1.0
2026-02-10 12:35:49,628 - INFO - Total PRISM time: 1.48s, Total LLM time: 190.93s
2026-02-10 12:35:49,629 - INFO - Evaluation 6: LTL Score = 1.0 (iterations: 1)
